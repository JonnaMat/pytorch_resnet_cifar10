{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonna/venv_embedl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from models import mobilenetv2, resnet56\n",
    "from torchvision.models import resnet50\n",
    "from embedl.plumbing.torch.metrics.target import Target\n",
    "from embedl.torch.pruning.methods import UniformPruning\n",
    "from embedl.torch.viewer import view_model\n",
    "from embedl.torch.metrics.performances import Flops  \n",
    "from embedl.torch.metrics.measure_performance import measure_flops\n",
    "import torchvision.datasets as datasets\n",
    "from embedl.torch.pruning.methods import plot_pruning_profile \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from embedl.torch.metrics.performances import Flops\n",
    "from embedl.torch.pruning.methods import (\n",
    "    PruningMethod,\n",
    "    ChannelPruningTactic,\n",
    ")\n",
    "from embedl.plumbing.torch.metrics.scorers import ChannelPruningScorer, PruningBalancer\n",
    "from embedl.torch.metrics.importance_scores import WeightMagnitude\n",
    "from embedl.plumbing.torch.pruning.method import apply_pruning_steps\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root=\"/home/jonna/data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    prec1 = 0\n",
    "    count = 0\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input_var = input.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 += accuracy(output.data, target)[0] * target.size(0)\n",
    "            # print(accuracy(output.data, target)[0])\n",
    "            count += target.size(0)\n",
    "\n",
    "    print(f\" * Prec@1 {prec1/count:.3f}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate before combining\n",
      " * Prec@1 95.320\n",
      " * Prec@1 95.200\n",
      " * Prec@1 94.690\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\n",
    "    \"/home/jonna/hyperparameter_sensitivity_pruning/experiments/cifar10/mobilenetv2/base_model/extended_grid_3/results/lr_10**-2.20_wd_10**-2.60/checkpoint_final.th\"\n",
    ")[\"state_dict\"]\n",
    "state_dict = {key[7:]: weights for key, weights in state_dict.items()}\n",
    "\n",
    "mobilenet_top1 = mobilenetv2()\n",
    "mobilenet_top1.load_state_dict(state_dict)\n",
    "mobilenet_top1.cuda()\n",
    "\n",
    "state_dict = torch.load(\n",
    "    \"/home/jonna/hyperparameter_sensitivity_pruning/experiments/cifar10/mobilenetv2/base_model/extended_grid_4/results/lr_10**-2.40_wd_10**-2.20/checkpoint_final.th\"\n",
    ")[\"state_dict\"]\n",
    "state_dict = {key[7:]: weights for key, weights in state_dict.items()}\n",
    "\n",
    "mobilenet_top2 = mobilenetv2()\n",
    "mobilenet_top2.load_state_dict(state_dict)\n",
    "mobilenet_top2.cuda()\n",
    "\n",
    "state_dict = torch.load(\n",
    "    \"/home/jonna/hyperparameter_sensitivity_pruning/experiments/cifar10/mobilenetv2/base_model/extended_grid_4/results/lr_10**-2.20_wd_10**-2.20/checkpoint_final.th\"\n",
    ")[\"state_dict\"]\n",
    "state_dict = {key[7:]: weights for key, weights in state_dict.items()}\n",
    "\n",
    "mobilenet_top3 = mobilenetv2()\n",
    "mobilenet_top3.load_state_dict(state_dict)\n",
    "mobilenet_top3.cuda()\n",
    "\n",
    "print(\"Validate before combining\")\n",
    "\n",
    "validate(\n",
    "    val_loader, torch.nn.DataParallel(mobilenet_top1), nn.CrossEntropyLoss().cuda()\n",
    ")\n",
    "validate(\n",
    "    val_loader, torch.nn.DataParallel(mobilenet_top2), nn.CrossEntropyLoss().cuda()\n",
    ")\n",
    "validate(\n",
    "    val_loader, torch.nn.DataParallel(mobilenet_top3), nn.CrossEntropyLoss().cuda()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 10.000\n"
     ]
    }
   ],
   "source": [
    "sd1 = mobilenet_top1.state_dict()\n",
    "sd2 = mobilenet_top2.state_dict()\n",
    "sd3 = mobilenet_top3.state_dict()\n",
    "\n",
    "\n",
    "# Average all parameters\n",
    "for key in sd1:\n",
    "    sd2[key] = (sd1[key] + sd2[key] + sd3[key]) / 3.\n",
    "\n",
    "\n",
    "# Recreate model and load averaged state_dict (or use modelA/B)\n",
    "model = mobilenetv2()\n",
    "model.load_state_dict(sd2)\n",
    "validate(\n",
    "    val_loader, torch.nn.DataParallel(model), nn.CrossEntropyLoss().cuda()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_embedl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
