{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from models import mobilenetv2, resnet56\n",
    "from embedl.plumbing.torch.metrics.target import Target\n",
    "from embedl.torch.pruning.methods import UniformPruning\n",
    "from embedl.torch.viewer import view_model\n",
    "from embedl.torch.metrics.performances import Flops  \n",
    "from embedl.torch.metrics.measure_performance import measure_flops\n",
    "import torchvision.datasets as datasets\n",
    "from embedl.torch.pruning.methods import plot_pruning_profile \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from embedl.torch.metrics.performances import Flops\n",
    "from embedl.torch.pruning.methods import (\n",
    "    PruningMethod,\n",
    "    ChannelPruningTactic,\n",
    ")\n",
    "from embedl.plumbing.torch.metrics.scorers import ChannelPruningScorer, PruningBalancer\n",
    "from embedl.torch.metrics.importance_scores import WeightMagnitude\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root=\"/home/jonna/data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    prec1 = 0\n",
    "    count = 0\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input_var = input.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 += accuracy(output.data, target)[0] * target.size(0)\n",
    "            # print(accuracy(output.data, target)[0])\n",
    "            count += target.size(0)\n",
    "\n",
    "    print(f\" * Prec@1 {prec1/count:.3f}\")\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_embedl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
