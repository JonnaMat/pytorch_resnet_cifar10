{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import mobilenetv2, resnet56\n",
    "from embedl.plumbing.torch.metrics.target import Target\n",
    "from embedl.torch.pruning.methods import UniformPruning\n",
    "from embedl.torch.viewer import view_model\n",
    "from embedl.torch.metrics.performances import Flops  \n",
    "from embedl.torch.metrics.measure_performance import measure_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('/home/jonna/hyperparameter_sensitivity_pruning/experiments/cifar10/mobilenetv2/pruned_60/results/lr_10**-0.20_wd_10**-3.20/model_init.th')['state_dict']\n",
    "# view_model(m, [1,3,32,32])\n",
    "a = {x[7:] : y for x,y in m.items()}\n",
    "\n",
    "mm = torch.load('pruned_models/mobilenetv2_uniform_60.th')\n",
    "\n",
    "m = mm.load_state_dict(a)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_model(mm, [1,3,32,32] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {x[7:] : y for x,y in m.items()}\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mobilenetv2()\n",
    "input_shape = [1,3,32,32]       \n",
    "base_flops = measure_flops(\n",
    "    model=model,\n",
    "    input_shape=input_shape\n",
    ")\n",
    "pruning_method = UniformPruning(\n",
    "    target=Target(Flops(), fraction=0.2),\n",
    "    step_size=2\n",
    ")\n",
    "pruning_steps = pruning_method.prune(model, input_shape)\n",
    "pruned_flops = measure_flops(\n",
    "    model=model,\n",
    "    input_shape=input_shape\n",
    ")\n",
    "print(pruned_flops/base_flops) # 0.1980394686585399\n",
    "# torch.save(model, 'pruned_models/mobilenetv2_uniform_20.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_model(torch.load('pruned_models/mobilenetv2_uniform_20.th'), [1,3,32,32], compare_with=torch.load('pruned_models/mobilenetv2_uniform_60.th'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_embedl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
